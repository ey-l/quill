{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbbe54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "num_pattern = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
    "\n",
    "def canon_float(x, prec=DEDUP_PREC):\n",
    "    \"\"\"Round to a fixed precision to make dedup robust to tiny float noise.\"\"\"\n",
    "    return float(np.round(float(x), prec))\n",
    "\n",
    "def fmt_num(x):\n",
    "    \"\"\"Pretty numeric formatting in headers (avoid 1.0000, show 1).\"\"\"\n",
    "    x = float(x)\n",
    "    xi = int(round(x))\n",
    "    return str(xi) if abs(x - xi) < 10**-6 else FLOAT_FMT.format(x)\n",
    "\n",
    "def parse_bins(text):\n",
    "    \"\"\"Parse a 'bins' string like '[  0  18  35  45  65 100]' -> sorted unique floats.\"\"\"\n",
    "    vals = [canon_float(v) for v in num_pattern.findall(str(text))]\n",
    "    if not vals:\n",
    "        return []\n",
    "    vals = sorted(set(vals))\n",
    "    return vals\n",
    "\n",
    "def load_all_edges_for_attr(attr_name: str):\n",
    "    \"\"\"\n",
    "    Load <Attr>.csv and return a list of edge-lists (one per row/method),\n",
    "    already deduped & sorted within each list.\n",
    "    \"\"\"\n",
    "    path = Path(SPECS_DIR) / f\"{attr_name}.csv\"\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    df = pd.read_csv(path)\n",
    "    out = []\n",
    "    for _, row in df.iterrows():\n",
    "        edges = parse_bins(row.get(\"bins\", \"\"))\n",
    "        if len(edges) >= 2:\n",
    "            out.append(edges)\n",
    "    return out\n",
    "\n",
    "def union_intervals_from_edges(edge_lists):\n",
    "    \"\"\"\n",
    "    From multiple edge lists, build the union of UNIQUE intervals.\n",
    "    Intervals are represented as tuples: (lo, hi, right_closed)\n",
    "    where right_closed = True only for the last interval of its originating edge list.\n",
    "    Dedup uses (lo, hi, right_closed) after rounding.\n",
    "    \"\"\"\n",
    "    uniq = set()\n",
    "    for edges in edge_lists:\n",
    "        n = len(edges)\n",
    "        for i in range(n - 1):\n",
    "            lo = canon_float(edges[i])\n",
    "            hi = canon_float(edges[i + 1])\n",
    "            right_closed = (i == n - 2)\n",
    "            key = (lo, hi, right_closed)\n",
    "            uniq.add(key)\n",
    "    # Return sorted list by (lo, hi, right_closed)\n",
    "    return sorted(list(uniq), key=lambda t: (t[0], t[1], not t[2]))\n",
    "\n",
    "def union_thresholds_from_edges(edge_lists):\n",
    "    \"\"\"\n",
    "    From multiple edge lists, build the union of UNIQUE thresholds for '< thr' columns.\n",
    "    We skip the first (minimum) cut of each list; keep unique canonized values.\n",
    "    \"\"\"\n",
    "    thr = set()\n",
    "    for edges in edge_lists:\n",
    "        for t in edges[1:]:\n",
    "            thr.add(canon_float(t))\n",
    "    return sorted(list(thr))\n",
    "\n",
    "def make_interval_features(series: pd.Series, intervals, attr):\n",
    "    \"\"\"Create binary features for intervals (list of (lo, hi, right_closed)).\"\"\"\n",
    "    x = pd.to_numeric(series, errors=\"coerce\")\n",
    "    cols = {}\n",
    "    for (lo, hi, right_closed) in intervals:\n",
    "        if right_closed:\n",
    "            mask = (x >= lo) & (x <= hi)\n",
    "            col = f\"{attr}:[{fmt_num(lo)},{fmt_num(hi)}]\"\n",
    "        else:\n",
    "            mask = (x >= lo) & (x <  hi)\n",
    "            col = f\"{attr}:[{fmt_num(lo)},{fmt_num(hi)})\"\n",
    "        cols[col] = mask.astype(int)\n",
    "    return pd.DataFrame(cols, index=series.index)\n",
    "\n",
    "def make_threshold_features(series: pd.Series, thresholds, attr):\n",
    "    \"\"\"Create binary '< thr' features for unique thresholds.\"\"\"\n",
    "    x = pd.to_numeric(series, errors=\"coerce\")\n",
    "    cols = {}\n",
    "    for thr in thresholds:\n",
    "        col = f\"{attr}:<{fmt_num(thr)}\"\n",
    "        cols[col] = (x < thr).astype(int)\n",
    "    return pd.DataFrame(cols, index=series.index)\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(DIABETES_CSV)\n",
    "    attributes = [c for c in ATTRIBUTES if c != LABEL_COL]\n",
    "\n",
    "    feat_parts = []\n",
    "\n",
    "    for attr in attributes:\n",
    "        edge_lists = load_all_edges_for_attr(attr)\n",
    "        if not edge_lists:\n",
    "            # No spec file for this attribute -> skip\n",
    "            continue\n",
    "\n",
    "        if ENCODING_STYLE == \"bins\":\n",
    "            # build the union of unique intervals across all methods, then binarize\n",
    "            intervals = union_intervals_from_edges(edge_lists)\n",
    "            feats = make_interval_features(df[attr], intervals, attr)\n",
    "        else:\n",
    "            # build the union of unique thresholds across all methods, then binarize\n",
    "            thresholds = union_thresholds_from_edges(edge_lists)\n",
    "            feats = make_threshold_features(df[attr], thresholds, attr)\n",
    "\n",
    "        feat_parts.append(feats)\n",
    "\n",
    "    X = pd.concat(feat_parts, axis=1) if feat_parts else pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Keep label column (if present) as last\n",
    "    if LABEL_COL in ATTRIBUTES:\n",
    "        X[LABEL_COL] = df[LABEL_COL].values\n",
    "\n",
    "    out_path = \"diabetes-treefarms.csv\"\n",
    "    X.to_csv(os.path.join(\"./pima/input/\", out_path), index=False)\n",
    "    print(f\"Wrote {out_path} with shape {X.shape}\")\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c146e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote diabetes-treefarms.csv with shape (768, 2208)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- CONFIG ----------------\n",
    "DIABETES_CSV = \"./pima/input/diabetes.csv\"   # path to diabetes.csv\n",
    "SPECS_DIR    = \"./pima/scored_attributes\"              # directory containing Age.csv, BMI.csv, Glucose.csv, ...\n",
    "LABEL_COL    = \"Outcome\"        # kept (if present) at the end\n",
    "ATTRIBUTES   = [\"Age\", \"BMI\", \"Glucose\", \"Outcome\"]  # list of attributes to consider\n",
    "ENCODING_STYLE = \"thresholds\"         # \"bins\" (interval membership) or \"thresholds\" (cumulative <cut)\n",
    "FLOAT_FMT = \"{:.6g}\"            # column name formatting for numbers\n",
    "DEDUP_PREC = 12                 # rounding precision for comparing cuts/intervals\n",
    "# ---------------------------------------\n",
    "\n",
    "X = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f417b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lucid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
